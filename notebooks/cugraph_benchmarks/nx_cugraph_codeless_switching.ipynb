{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Performance of NetworkX with Rapids GPU-based nx_cugraph backend vs on cpu\n",
    "# Skip notebook test\n",
    "This notebook benchmarks the use of nx_cugraph as dispatcher for NetworkX algorithms. \n",
    "\n",
    "It runs  Betweenness Centrality, Breadth First Search, Louvain Community Detectio and collects times for these runs with and without nx_cugraph backend and graph caching enabled. nx_cugraph is a registered NetworkX backend. Using it is a codeless change. \n",
    "\n",
    "In the notebook these variables are set via the [NetworkX config package](https://networkx.org/documentation/stable/reference/backends.html#networkx.utils.configs.NetworkXConfig). They can be set at the command line as well.\n",
    "\n",
    "### See this example from GTC Spring 2024\n",
    "\n",
    "\n",
    "\n",
    "Here is a sample minimal script to demonstrate codeless changes to use nx-cugraph.\n",
    "bc_demo.ipy:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "%time result = nx.betweenness_centrality(G, k=10)\n",
    "```\n",
    "Running it with the nx-cugraph backend looks like this:\n",
    "```\n",
    "user@machine:/# ipython bc_demo.ipy\n",
    "CPU times: user 7min 38s, sys: 5.6 s, total: 7min 44s\n",
    "Wall time: 7min 44s\n",
    "\n",
    "user@machine:/# NETWORKX_BACKEND_PRIORITY=cugraph ipython bc_demo.ipy\n",
    "CPU times: user 18.4 s, sys: 1.44 s, total: 19.9 s\n",
    "Wall time: 20 s\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This installs the NetworkX cuGraph dispatcher if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import nx_cugraph\n",
    "except ModuleNotFoundError:\n",
    "    os.system('conda install -c rapidsai -c conda-forge -c nvidia nx-cugraph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is boiler plate NetworkX code to run:\n",
    "* betweenness Centrality\n",
    "* Bredth first Search\n",
    "* Louvain community detection\n",
    "\n",
    "and collect times. it is completely unaware of cugraph or GPU-based tools.\n",
    "[NetworkX configurations](https://networkx.org/documentation/stable/reference/utils.html#backends) can determine how they are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algos(G):\n",
    "\n",
    "    time_begin = time.time() \n",
    "    result = nx.betweenness_centrality(G, k=1)\n",
    "    time_bc =  time.time() - time_begin\n",
    "    print(\"Done bc, time=\"+ str(time_bc))\n",
    "    time_begin = time.time()\n",
    "    result =  nx.bfs_tree(G,source=1)\n",
    "    time_bfs = time.time() - time_begin\n",
    "    print(\"Done bfs, time=\"+ str(time_bfs))\n",
    "    time_begin = time.time()\n",
    "    result = nx.community.louvain_communities(G,threshold=1e-04)\n",
    "    time_louvain =  time.time() - time_begin\n",
    "    print(\"Done louvain, time=\"+ str(time_louvain))\n",
    "    return time_bc + time_bfs + time_louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads a patent citation dataset containing 3774768 nodes and 16518948 edges and loads it into a NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./data/cit-Patents.csv\"\n",
    "\n",
    "if os.path.exists(filepath):\n",
    "    print(\"File found\")\n",
    "    url = filepath\n",
    "else:\n",
    "    url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the NetworkX dispatcher with an environment variable or in code using NetworkX config package which is new to [NetworkX 3.3 config](https://networkx.org/documentation/stable/reference/backends.html#networkx.utils.configs.NetworkXConfig).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.config[\"backend_priority\"]=['cugraph']\n",
    "nx.config[\"cache_converted_graphs\"]= True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the algorithms on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_algos(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is running the same algorithms on CPU without nx-cugraph. This will take about 40 minutes. Compared to the roughly 90 seconds above. That is more than a 25x speedup by loading the graph once and running the three algorithms on GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off graph caching and the nx-cugraph backend and rerun\n",
    "nx.config[\"cache_converted_graphs\"]= False\n",
    "nx.config[\"backend_priority\"]=[]\n",
    "run_algos(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2024, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
